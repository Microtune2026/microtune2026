defaults:
  - env: discrete_actions
  - base_linear
  - override env/state_selector@env.state_selector_train: df_randombuffer #df_fullsequential
  - _self_

TRAINING_COVERAGE: 9 # Coverage of the total states present in dataset. 1.0 means that almost all the dataset will be covered (depends also on the random distribution that may repeat twice the same state)
TRAINING_STEPS_PER_EPISODE: 68    # Important to take benefit of the decreasing exploration vs exploitation tradeoff

agent:
  policy:
    _target_: bandits.policy_linucb_discounted.DLinUCBPolicy
    delta: 0.1
    gamma: 0.1
    _lambda: 1.
