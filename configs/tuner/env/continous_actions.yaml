defaults:
  - observations: prod_optimal
  - state_selector@state_selector_train: df_randombuffer #df_fullrandom
  - state_selector@state_selector_test: df_topdownrocker 

wrapper:
  _target_: bandits.gym_env.VSMonitor
  env:
    _partial_: true
    _target_: bandits.gym_env.VSEnvContinousSpace
#    state_selector: ${...state_selector_train} # tuner.env.
    reward: ${tuner.reward.learn}
    notify_react: ${....TRAINING_USE_SLA_PROTECT} # tuner.
    max_steps_per_episode: ${....TRAINING_STEPS_PER_EPISODE} # tuner.
    on_terminate: -1 # If >=0 Stop the episode, if STAY action is done without any regret! In such a case reward is increased + on_terminate value
    verbose: ${xtraverbosity}

wrapper_test:
  _target_: bandits.gym_env.VSMonitor
  env:
    _partial_: true
    _target_: bandits.gym_env.VSEnvContinousSpace
#    state_selector: ${...state_selector_test} # tuner.env.
    reward: ${tuner.reward.test}
    notify_react: ${....TEST_USE_SLA_PROTECT} # tuner.
    max_steps_per_episode: ${....TEST_STEPS_PER_EPISODE} # If val<0, abs(val) will be a multiple of buffer values count
    on_terminate: -1 # If >=0 Stop the episode, if STAY action is done without any regret! In such a case reward is increased + on_terminate value
    verbose: ${verbosity}
  perf_meter:
    _target_: bandits.perf_meter.PerfMeter
    name: NA
    
