defaults:
  - actions: lessoneplusone      # The Min and Max action values. Arms count and the position of the "STAY" arm are depending on it.
  - reward: continousv3E
  - env: discrete_actions
  - override env/observations: empty
  - _self_

NORMALIZE_OBS: False
TEST_USE_SLA_PROTECT: False   # Must be like that (False)
TEST_EPISODES_COUNT: -2    # If <0, abs(EPISODES_COUNT) is a multiple of workloads count 
TEST_STEPS_PER_EPISODE: -2 # If val<0, abs(val) will be a multiple of buffer values count

# Base config for all baselines
agent:
  _target_: bandits.agent.VSAgent
  policy:
    _target_: bandits.policy_baselines.OraclePolicy
    actions: ${...actions} 
    ctx: ${...env.observations.elems}

# ==== NO TRAINING ALLOWED ====
# Discard training wrapper
reward: 
  learn: null  
env:
  state_selector_train: null
  wrapper: null
  wrapper_test:
    perf_meter:
      baseline: 2 # Oracle is 1, other will be set to higher

TRAINING_COVERAGE: 0 # Coverage of the total states present in dataset. 1.0 means that almost all the dataset will be covered (depends also on the random distribution that may repeat twice the same state)
TRAINING_STEPS_PER_EPISODE: 0    # Important to take benefit of the decreasing exploration vs explotation tradeoff

# In Labo mode, we consider that having usage of client's latency in LinUCB context, in both learning and test, is not an issue
# In Prod mode, we can access client's latency only during learning process. Latency cannot be part of the LinUCB context. The only viable and comparable baseline is BFR (Buffer Filling Rate) baseline.
#LABO_EXPE is True ?
#TRAINING_USE_SLA_PROTECT: True #use or NOT Use the reactive mode to protect the SLA. Let see where we are going without this protection...
#TEST_USE_SLA_PROTECT: True #True if "sysbench_filtered.latency_mean" in OBSERVATION_SPACE_ELEMS else False

#LABO_EXPE is False ?
#TRAINING_USE_SLA_PROTECT: False #It makes no sense to put it at True if we cannot use it in test..


