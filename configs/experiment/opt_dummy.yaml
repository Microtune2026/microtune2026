# @package _global_
defaults:
  - base_optuna
  - _self_

version: 11
n_trials: 2 # job.num will be in range [0, n_trials-1]
n_seeds: 2

learning_rate: 0.9

hydra:
#  mode: RUN
  #sweep:
    #dir: /var/local/data/trainer/multirun/ppo_${now:%Y%m%d}-${now:%H%M%S}
  sweeper:
    params:
      learning_rate: range(0.5, 1.2, step=0.05)

tuner:
  TRAINING_COVERAGE: 0.2 # Coverage of the total states present in dataset. 1.0 means that almost all the dataset will be covered (depends also on the random distribution that may repeat twice the same state)
  TRAINING_STEPS_PER_EPISODE: 16    # Important to take benefit of the decreasing exploration vs explotation tradeoff
  agent:
    policy:
      learning_rate: ${learning_rate}
