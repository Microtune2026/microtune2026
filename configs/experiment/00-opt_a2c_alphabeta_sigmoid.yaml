# @package _global_
defaults:
  - base_optuna
  - override /tuner: a2c
  - override /tuner/reward: sigmoidhybriddiscretmoveidelta
  - _self_

info: A2C with Sigmoid reward and hyper params optim with Optuna + fixed ALPHA=0.2 and BETA=0 + Optimized OBS (David) + cleaned WL (c98, Yif)

n_seeds: 3
n_jobs: 3 # Number of parallel trainings with different seed
n_trials: 60
hydra_launcher_n_jobs: 4 # Number of trials in parallel with Optuna

REW_ALPHA_COEF: 0.2
REW_BETA_COEF: 0
learning_rate: 0.0003
gamma: 0.99
n_steps: 5

hydra:
  sweeper:
    params:
      learning_rate: range(0.0001,0.001, step=0.0001)
      gamma:  range(0.90,0.996, step=0.004) # Default 0.99. Lower value enforce reward values earlier (on first steps)
      n_steps: range(3,60, step=5)



tuner:
  TRAINING_COVERAGE: 9
  agent:
    policy:
      learning_rate: ${learning_rate}
      gamma: ${gamma}
      n_steps:  ${n_steps}