# @package _global_
defaults:
  - base
  - override /tuner: ddpg
  - override /tuner/reward: sigmoidhybriddiscretmoveidelta
  - _self_

info: DDPG with fixed hyper-parameters and basic sweep on multiple seeds + Sigmoid reward +  Optimized OBS (Dav.) + cleaned WL (c98, Yif.)
n_seeds: 1   # Nb seeds per trials
n_jobs: 1 # Number of parallel trainings with different seed of a trial
hydra_launcher_n_jobs: 4 # Number of trials in parallel with Optuna

REW_ALPHA_COEF: 0.2
REW_BETA_COEF: 0

# Best params: (learning_rate=0.0005 buffer_size=500000 batch_size=128 gamma=0.8600000000000001 tau=0.246 noise_sigma=0.35000000000000003 train_freq=33)

learning_rate: 0.0005
buffer_size: 500000
batch_size: 128
gamma: 0.86
tau: 0.246
noise_sigma: 0.35
train_freq: 33



hydra:
  sweeper:
    params:
      RND_SEED: range(4242, 4252, step=1)
tuner:
  TRAINING_COVERAGE: 9
  agent:
    policy:
      learning_rate: ${learning_rate}
      buffer_size: ${buffer_size}
      batch_size: ${batch_size}
      action_noise:
        noise_sigma: ${noise_sigma}
      gamma: ${gamma}
      tau: ${tau}
      train_freq: ${train_freq}
#      use_sde: ${use_sde}
