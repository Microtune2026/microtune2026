# @package _global_
defaults:
  - base_optuna
  - override /tuner: linucb_kfoofw
  - override /tuner/reward: sigmoidhybriddiscretmoveidelta
  - _self_

info: LinUCB (kfoofw) hyper params optim with Optuna and variable reward ALPHA in [0,1] and BETA in [0,1] with Optimized OBS (David)

n_trials: 80 # job.num will be in range [0, n_trials-1]
n_seeds: 2
n_jobs: 2 # Number of parallel trainings with different seed
hydra_launcher_n_jobs: 5 # Number of trials in parallel with Optuna

REW_ALPHA_COEF: 1
REW_BETA_COEF: 0
learning_rate: 0.9

hydra:
  sweeper:
    params:
      REW_ALPHA_COEF: choice(-1, 0, 0.2, 0.4, 0.6, 0.8, 1)
      REW_BETA_COEF:  choice(0, 0.2, 0.4, 0.6, 0.8, 1)
      learning_rate: range(0.5, 1.2, step=0.1)

tuner:
  TRAINING_COVERAGE: 2
  agent:
    policy:
      learning_rate: ${learning_rate}
