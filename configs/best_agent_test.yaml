# Get conf by running --cfg job --resolve

# State selector choices, env/datasource/state_selector:
# df_fullrandom
# df_randombuffer - Choix DD avec HSLinUCB mais pb. singular matrix avec KFOO
# df_sequential - At each reset choose the workload from the current episode index, go to the top or bottom state of the workload as specified by topdown argument.
# df_fullsequential - Choix PR, Optmal? - Start at the begining of the dataset and go to the next state at each reset. When bottom state is reached, next reset will go to the next workload (auto rewind)
# df_topdownrocker - Especially for tests Start sequentialy each workload twice. First from Top, second from Bottom
# df_randomtopdown - Starts randomly at each Reset from Top buffer value or Bottom buffer value
# db_live - Connected to a live database, at each reset do not touch the buffer value

# All agents:
# linucb_kfoo (LinUCB)
# linucb_hs   (HSLinUCB, i.e. HorizontalScaling LinUCB)
# ppo
# dqn
# a2c
# sac
# ddpg

# python run_best_agent.py tuner=ppo
# python run_best_agent.py +experiment=ppo ++n_trials=10

defaults:
  - best_agent
  - tuner@oracle: oracle
  - tuner@baseline: bfr
  - tuner@baseline2: basic
  - tuner@baseline3: chr
  - _self_


# Ensure to use the same episodes and step
# Ensure to use the same actions and reward than the Linear or NN models
oracle:
  TEST_EPISODES_COUNT: ${tuner.TEST_EPISODES_COUNT}
  TEST_STEPS_PER_EPISODE: ${tuner.TEST_STEPS_PER_EPISODE}
  actions: ${tuner.actions}
  reward: 
    test: ${tuner.reward.test}

baseline:
  TEST_EPISODES_COUNT: ${tuner.TEST_EPISODES_COUNT}
  TEST_STEPS_PER_EPISODE: ${tuner.TEST_STEPS_PER_EPISODE}
  actions: ${tuner.actions}
  reward: 
    test: ${tuner.reward.test}

baseline2:
  TEST_EPISODES_COUNT: ${tuner.TEST_EPISODES_COUNT}
  TEST_STEPS_PER_EPISODE: ${tuner.TEST_STEPS_PER_EPISODE}
  actions: ${tuner.actions}
  reward: 
    test: ${tuner.reward.test}

baseline3:
  TEST_EPISODES_COUNT: ${tuner.TEST_EPISODES_COUNT}
  TEST_STEPS_PER_EPISODE: ${tuner.TEST_STEPS_PER_EPISODE}
  actions: ${tuner.actions}
  reward: 
    test: ${tuner.reward.test}

